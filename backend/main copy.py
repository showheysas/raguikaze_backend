from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
import chromadb
import os
from dotenv import load_dotenv

# .env ã‹ã‚‰ OpenAI API ã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Chromaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆv0.4+å½¢å¼ï¼‰
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_collection("alctax-act")

# FastAPI ã‚¢ãƒ—ãƒªåˆæœŸåŒ–
app = FastAPI()

# CORSï¼ˆFlutterãªã©ã‹ã‚‰ã®é€šä¿¡è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªã§ã¯åˆ¶é™ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
class AskRequest(BaseModel):
    query: str
    kazemode: bool  # Trueãªã‚‰è—¤äº•é¢¨ãƒ¢ãƒ¼ãƒ‰

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class AskResponse(BaseModel):
    answer: str
    references: list[str]

# POST /ask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/ask", response_model=AskResponse)
async def ask_law(req: AskRequest):
    query = req.query
    kazemode = req.kazemode
    print(f"ğŸŸ¦ å—ä¿¡ã‚¯ã‚¨ãƒª: {query} | é¢¨ãƒ¢ãƒ¼ãƒ‰: {kazemode}")

    # âœ… OpenAIã§Embeddingç”Ÿæˆï¼ˆ1536æ¬¡å…ƒï¼‰
    embedding_response = client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    )
    query_embedding = embedding_response.data[0].embedding

    # âœ… Chromaãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆOpenAIåŸ‹ã‚è¾¼ã¿ã¨ä¸€è‡´ï¼‰
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=5
    )

    # é–¢é€£æ¡æ–‡ã‚’å–å¾—
    contexts = results.get("documents", [[]])[0]
    joined_context = "\n---\n".join(contexts)

    # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸã‚¹ã‚¿ã‚¤ãƒ«
    if kazemode:
        style = (
            "ã‚ãªãŸã¯è—¤äº•é¢¨æœ¬äººã§ã™ã€‚"
            "é…’ç¨æ³•ã®å†…å®¹ã‚’ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¾ã™ã€‚"
            "ä¾‹ãˆã‚„é›‘è«‡ã‚’äº¤ãˆãªãŒã‚‰ã€å£èªä½“ã§ã€ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ãŸé›°å›²æ°—ã§ç­”ãˆã¦ãã ã•ã„ã€‚"
        )
    else:
        style = (
            "ã‚ãªãŸã¯æ³•å¾‹ã«è©³ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "è³ªå•ã«å¯¾ã—ã¦æ­£ç¢ºã§ç°¡æ½”ã«ã€é…’ç¨æ³•ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚"
        )

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹æˆ
    prompt = f"""{style}

ä»¥ä¸‹ã®æ³•ä»¤æ¡æ–‡ã‚’å‚è€ƒã«ã€æ¬¡ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
---æ³•ä»¤æŠœç²‹---
{joined_context}

è³ªå•ï¼š
{query}
"""

    # GPT-4oã§å›ç­”ç”Ÿæˆ
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "user", "content": prompt}
        ]
    )
    answer = response.choices[0].message.content.strip()

    return AskResponse(answer=answer, references=contexts)
